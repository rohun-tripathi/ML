{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib import learn\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"data/final_train.csv\")\n",
    "\n",
    "trY = df['Item_Outlet_Sales']\n",
    "\n",
    "df.drop(['Item_Identifier'], axis=1, inplace=True)\n",
    "df.drop(['Item_Outlet_Sales'], axis=1, inplace=True)\n",
    "\n",
    "df = df.astype(np.float32)\n",
    "\n",
    "scaler_X = StandardScaler(with_mean=True, with_std=True)\n",
    "trX = scaler_X.fit_transform(df)\n",
    "\n",
    "trX, tsX, trY, tsY = train_test_split(trX, trY, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Class that defines the behavior of the RBM\n",
    "class RBM(object):\n",
    "    \n",
    "    def __init__(self, input_size, output_size, epochs=5, learning_rate=1, batchsize=1):\n",
    "        #Defining the hyperparameters\n",
    "        self._input_size = input_size #Size of input\n",
    "        self._output_size = output_size #Size of output\n",
    "        self.epochs = epochs #Amount of training iterations\n",
    "        self.learning_rate = learning_rate #The step used in gradient descent\n",
    "        self.batchsize = batchsize #The size of how much data will be used for training per sub iteration\n",
    "        \n",
    "        #Initializing weights and biases as matrices full of zeroes\n",
    "        self.w = np.zeros([input_size, output_size], np.float32) #Creates and initializes the weights with 0\n",
    "        self.hb = np.zeros([output_size], np.float32) #Creates and initializes the hidden biases with 0\n",
    "        self.vb = np.zeros([input_size], np.float32) #Creates and initializes the visible biases with 0\n",
    "\n",
    "\n",
    "    #Fits the result from the weighted visible layer plus the bias into a sigmoid curve\n",
    "    def prob_h_given_v(self, visible, w, hb):\n",
    "        #Sigmoid \n",
    "        return tf.nn.sigmoid(tf.matmul(visible, w) + hb)\n",
    "\n",
    "    #Fits the result from the weighted hidden layer plus the bias into a sigmoid curve\n",
    "    def prob_v_given_h(self, hidden, w, vb):\n",
    "        return tf.nn.sigmoid(tf.matmul(hidden, tf.transpose(w)) + vb)\n",
    "    \n",
    "    #Generate the sample probability\n",
    "    def sample_prob(self, probs):\n",
    "        return tf.nn.relu(tf.sign(probs - tf.random_uniform(tf.shape(probs))))\n",
    "\n",
    "    #Training method for the model\n",
    "    def train(self, X):\n",
    "        #Create the placeholders for our parameters\n",
    "        _w = tf.placeholder(\"float\", [self._input_size, self._output_size])\n",
    "        _hb = tf.placeholder(\"float\", [self._output_size])\n",
    "        _vb = tf.placeholder(\"float\", [self._input_size])\n",
    "        \n",
    "        prv_w = np.zeros([self._input_size, self._output_size], np.float32) #Creates and initializes the weights with 0\n",
    "        prv_hb = np.zeros([self._output_size], np.float32) #Creates and initializes the hidden biases with 0\n",
    "        prv_vb = np.zeros([self._input_size], np.float32) #Creates and initializes the visible biases with 0\n",
    "\n",
    "        \n",
    "        cur_w = np.zeros([self._input_size, self._output_size], np.float32)\n",
    "        cur_hb = np.zeros([self._output_size], np.float32)\n",
    "        cur_vb = np.zeros([self._input_size], np.float32)\n",
    "        v0 = tf.placeholder(\"float\", [None, self._input_size])\n",
    "        \n",
    "        #Initialize with sample probabilities\n",
    "        h0 = self.sample_prob(self.prob_h_given_v(v0, _w, _hb))\n",
    "        v1 = self.sample_prob(self.prob_v_given_h(h0, _w, _vb))\n",
    "        h1 = self.prob_h_given_v(v1, _w, _hb)\n",
    "        \n",
    "        #Create the Gradients\n",
    "        positive_grad = tf.matmul(tf.transpose(v0), h0)\n",
    "        negative_grad = tf.matmul(tf.transpose(v1), h1)\n",
    "        \n",
    "        #Update learning rates for the layers\n",
    "        update_w = _w + self.learning_rate *(positive_grad - negative_grad) / tf.to_float(tf.shape(v0)[0])\n",
    "        update_vb = _vb +  self.learning_rate * tf.reduce_mean(v0 - v1, 0)\n",
    "        update_hb = _hb +  self.learning_rate * tf.reduce_mean(h0 - h1, 0)\n",
    "        \n",
    "        #Find the error rate\n",
    "        err = tf.reduce_mean(tf.square(v0 - v1))\n",
    "        \n",
    "        #Training loop\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            #For each epoch\n",
    "            for epoch in range(self.epochs):\n",
    "                #For each step/batch\n",
    "                for start, end in zip(range(0, len(X), self.batchsize),range(self.batchsize,len(X), self.batchsize)):\n",
    "                    batch = X[start:end]\n",
    "                    #Update the rates\n",
    "                    cur_w = sess.run(update_w, feed_dict={v0: batch, _w: prv_w, _hb: prv_hb, _vb: prv_vb})\n",
    "                    cur_hb = sess.run(update_hb, feed_dict={v0: batch, _w: prv_w, _hb: prv_hb, _vb: prv_vb})\n",
    "                    cur_vb = sess.run(update_vb, feed_dict={v0: batch, _w: prv_w, _hb: prv_hb, _vb: prv_vb})\n",
    "                    prv_w = cur_w\n",
    "                    prv_hb = cur_hb\n",
    "                    prv_vb = cur_vb\n",
    "                error=sess.run(err, feed_dict={v0: X, _w: cur_w, _vb: cur_vb, _hb: cur_hb})\n",
    "                print('Epoch: {} --> Reconstruction error={}'.format(epoch, error))\n",
    "            self.w = prv_w\n",
    "            self.hb = prv_hb\n",
    "            self.vb = prv_vb\n",
    "\n",
    "    #Create expected output for our DBN\n",
    "    def rbm_outpt(self, X):\n",
    "        input_X = tf.constant(X)\n",
    "        _w = tf.constant(self.w)\n",
    "        _hb = tf.constant(self.hb)\n",
    "        out = tf.nn.sigmoid(tf.matmul(input_X, _w) + _hb)\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            return sess.run(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RBM: 0  10 --> 150\n",
      "RBM: 1  150 --> 1\n"
     ]
    }
   ],
   "source": [
    "RBM_hidden_sizes = [150, 1]\n",
    "\n",
    "#Since we are training, set input as training data\n",
    "inpX = trX\n",
    "\n",
    "#Create list to hold our RBMs\n",
    "rbm_list = []\n",
    "\n",
    "#Size of inputs is the number of inputs in the training set\n",
    "input_size = inpX.shape[1]\n",
    "\n",
    "#For each RBM we want to generate\n",
    "for i, size in enumerate(RBM_hidden_sizes):\n",
    "    print('RBM: {}  {} --> {}'.format(i, input_size, size))\n",
    "    rbm_list.append(RBM(input_size, size, epochs=20, learning_rate=0.5, batchsize=20))\n",
    "    input_size = size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New RBM:\n",
      "Epoch: 0 --> Reconstruction error=0.8700782060623169\n",
      "Epoch: 1 --> Reconstruction error=0.8636254668235779\n",
      "Epoch: 2 --> Reconstruction error=0.8611057996749878\n",
      "Epoch: 3 --> Reconstruction error=0.8589401841163635\n",
      "Epoch: 4 --> Reconstruction error=0.8584511280059814\n",
      "Epoch: 5 --> Reconstruction error=0.8574615716934204\n",
      "Epoch: 6 --> Reconstruction error=0.8572171926498413\n",
      "Epoch: 7 --> Reconstruction error=0.854599118232727\n",
      "Epoch: 8 --> Reconstruction error=0.8541574478149414\n",
      "Epoch: 9 --> Reconstruction error=0.8540276288986206\n",
      "Epoch: 10 --> Reconstruction error=0.8531795740127563\n",
      "Epoch: 11 --> Reconstruction error=0.8534522652626038\n",
      "Epoch: 12 --> Reconstruction error=0.8541721105575562\n",
      "Epoch: 13 --> Reconstruction error=0.8526024222373962\n",
      "Epoch: 14 --> Reconstruction error=0.8528524041175842\n",
      "Epoch: 15 --> Reconstruction error=0.8524441719055176\n",
      "Epoch: 16 --> Reconstruction error=0.8516952395439148\n",
      "Epoch: 17 --> Reconstruction error=0.8526866436004639\n",
      "Epoch: 18 --> Reconstruction error=0.8516984581947327\n",
      "Epoch: 19 --> Reconstruction error=0.8511568903923035\n",
      "New RBM:\n",
      "Epoch: 0 --> Reconstruction error=0.2604488432407379\n",
      "Epoch: 1 --> Reconstruction error=0.2545413076877594\n",
      "Epoch: 2 --> Reconstruction error=0.2532344162464142\n",
      "Epoch: 3 --> Reconstruction error=0.253151535987854\n",
      "Epoch: 4 --> Reconstruction error=0.25212013721466064\n",
      "Epoch: 5 --> Reconstruction error=0.25169235467910767\n",
      "Epoch: 6 --> Reconstruction error=0.25179028511047363\n",
      "Epoch: 7 --> Reconstruction error=0.25251343846321106\n",
      "Epoch: 8 --> Reconstruction error=0.2523405849933624\n",
      "Epoch: 9 --> Reconstruction error=0.25160953402519226\n",
      "Epoch: 10 --> Reconstruction error=0.25258395075798035\n",
      "Epoch: 11 --> Reconstruction error=0.2517901360988617\n",
      "Epoch: 12 --> Reconstruction error=0.25094133615493774\n",
      "Epoch: 13 --> Reconstruction error=0.25101181864738464\n",
      "Epoch: 14 --> Reconstruction error=0.2509543001651764\n",
      "Epoch: 15 --> Reconstruction error=0.25201794505119324\n",
      "Epoch: 16 --> Reconstruction error=0.2505449056625366\n",
      "Epoch: 17 --> Reconstruction error=0.2513163685798645\n",
      "Epoch: 18 --> Reconstruction error=0.25134244561195374\n",
      "Epoch: 19 --> Reconstruction error=0.25140199065208435\n"
     ]
    }
   ],
   "source": [
    "#For each RBM in our list\n",
    "for rbm in rbm_list:\n",
    "    print('New RBM:')\n",
    "    #Train a new one\n",
    "    rbm.train(inpX)\n",
    "    inpX = inpX.astype(np.float32)\n",
    "    #Return the output layer\n",
    "    inpX = rbm.rbm_outpt(inpX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "total_len = trX.shape[0]\n",
    "\n",
    "# Parameters\n",
    "training_epochs = 1250\n",
    "batch_size = 20\n",
    "display_step = 100\n",
    "# Network Parameters\n",
    "n_input = trX.shape[1]\n",
    "\n",
    "# tf Graph input\n",
    "x = tf.placeholder(\"float\", [None, trX.shape[1]])\n",
    "y = tf.placeholder(\"float\", [None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create model\n",
    "def multilayer_perceptron(x, weights, biases):\n",
    "    # Hidden layer with RELU activation\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "\n",
    "#     # Hidden layer with RELU activation\n",
    "#     layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "#     layer_2 = tf.nn.relu(layer_2)\n",
    "\n",
    "    # Output layer with linear activation\n",
    "    out_layer = tf.matmul(layer_1, weights['out']) + biases['out']\n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def load_from_rbms(rbm_list):\n",
    "        #If everything is correct, bring over the weights and biases\n",
    "        weights = {}\n",
    "        biases = {}\n",
    "        for i in range(len(rbm_list)):\n",
    "            if i == len(rbm_list)-1:\n",
    "                s = 'out'\n",
    "                weights[s] = tf.Variable(rbm_list[i].w)\n",
    "                biases[s] = tf.Variable(rbm_list[i].hb)\n",
    "            else:\n",
    "                s = 'h' + str(i+1)\n",
    "                weights[s] = tf.Variable(rbm_list[i].w)\n",
    "                s = 'b' + str(i+1)\n",
    "                biases[s] = tf.Variable(rbm_list[i].hb)\n",
    "        return weights, biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "weights, biases = load_from_rbms(rbm_list)\n",
    "\n",
    "# Construct model\n",
    "pred = multilayer_perceptron(x, weights, biases)\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.sqrt(tf.reduce_mean(tf.square(pred-y)))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost = 920571.478947368\n",
      "Epoch: 0101 cost = 1882.324786270\n",
      "Epoch: 0201 cost = 1719.933937260\n",
      "Epoch: 0301 cost = 1704.744489061\n",
      "Epoch: 0401 cost = 1698.501349627\n",
      "Epoch: 0501 cost = 1695.191352496\n",
      "Epoch: 0601 cost = 1693.138752399\n",
      "Epoch: 0701 cost = 1691.750159762\n",
      "Epoch: 0801 cost = 1690.759858141\n",
      "Epoch: 0901 cost = 1690.031583873\n",
      "Epoch: 1001 cost = 1689.478513269\n",
      "Epoch: 1101 cost = 1689.046579890\n",
      "Epoch: 1201 cost = 1688.698512670\n",
      "Optimization Finished!\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Training cycle\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0.\n",
    "    total_batch = int(total_len/batch_size)\n",
    "    # Loop over all batches\n",
    "    for i in range(total_batch-1):\n",
    "        batch_x = trX[i*batch_size:(i+1)*batch_size]\n",
    "        batch_y = trY[i*batch_size:(i+1)*batch_size]\n",
    "        # Run optimization op (backprop) and cost op (to get loss value)\n",
    "        _, c, p = sess.run([optimizer, cost, pred], feed_dict={x: batch_x,\n",
    "                                                      y: batch_y})\n",
    "        # Compute average loss\n",
    "        avg_cost += c / total_batch\n",
    "\n",
    "    # Display logs per epoch step\n",
    "    if epoch % display_step == 0:\n",
    "        print (\"Epoch:\", '%04d' % (epoch+1), \"cost =\", \\\n",
    "            \"{:.9f}\".format(avg_cost))\n",
    "\n",
    "print (\"Optimization Finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1684.07\n"
     ]
    }
   ],
   "source": [
    "# Test model\n",
    "error = tf.square(pred - y)\n",
    "# Calculate accuracy\n",
    "accuracy = tf.sqrt(tf.reduce_mean(tf.cast(error, \"float\")))\n",
    "print(sess.run(accuracy, feed_dict={x: tsX, y: tsY}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
